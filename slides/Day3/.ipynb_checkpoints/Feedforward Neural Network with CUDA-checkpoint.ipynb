{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784       # The image size = 28 x 28 = 784\n",
    "hidden_size = 100      # The number of nodes at the hidden layer\n",
    "num_classes = 10       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 100       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the loading process of train_dataset to make the learning process independent of data orderness, but the order of test_loader remains to examine whether we can handle unspecified bias order of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4, \n",
    "                                          pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=4, \n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]\n",
      " - Numpy Shape: (60000, 28, 28)\n",
      " - Tensor Shape: torch.Size([60000, 28, 28])\n",
      " - min: tensor(0.)\n",
      " - max: tensor(1.)\n",
      " - mean: tensor(0.1307)\n",
      " - std: tensor(0.3081)\n",
      " - var: tensor(0.0949)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset.train_data\n",
    "train_data = train_dataset.transform(train_data.numpy())\n",
    "\n",
    "print('[Train]')\n",
    "print(' - Numpy Shape:', train_dataset.train_data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', train_dataset.train_data.size())\n",
    "print(' - min:', torch.min(train_data))\n",
    "print(' - max:', torch.max(train_data))\n",
    "print(' - mean:', torch.mean(train_data))\n",
    "print(' - std:', torch.std(train_data))\n",
    "print(' - var:', torch.var(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 0.3490\n",
      "Epoch [1/10], Step [200/600], Loss: 0.3231\n",
      "Epoch [1/10], Step [300/600], Loss: 0.2564\n",
      "Epoch [1/10], Step [400/600], Loss: 0.3018\n",
      "Epoch [1/10], Step [500/600], Loss: 0.1351\n",
      "Epoch [1/10], Step [600/600], Loss: 0.1467\n",
      "Epoch [2/10], Step [100/600], Loss: 0.1353\n",
      "Epoch [2/10], Step [200/600], Loss: 0.1113\n",
      "Epoch [2/10], Step [300/600], Loss: 0.1273\n",
      "Epoch [2/10], Step [400/600], Loss: 0.1318\n",
      "Epoch [2/10], Step [500/600], Loss: 0.1903\n",
      "Epoch [2/10], Step [600/600], Loss: 0.2276\n",
      "Epoch [3/10], Step [100/600], Loss: 0.0991\n",
      "Epoch [3/10], Step [200/600], Loss: 0.1721\n",
      "Epoch [3/10], Step [300/600], Loss: 0.1989\n",
      "Epoch [3/10], Step [400/600], Loss: 0.1399\n",
      "Epoch [3/10], Step [500/600], Loss: 0.1003\n",
      "Epoch [3/10], Step [600/600], Loss: 0.1115\n",
      "Epoch [4/10], Step [100/600], Loss: 0.0942\n",
      "Epoch [4/10], Step [200/600], Loss: 0.0742\n",
      "Epoch [4/10], Step [300/600], Loss: 0.0878\n",
      "Epoch [4/10], Step [400/600], Loss: 0.0617\n",
      "Epoch [4/10], Step [500/600], Loss: 0.2161\n",
      "Epoch [4/10], Step [600/600], Loss: 0.0677\n",
      "Epoch [5/10], Step [100/600], Loss: 0.0623\n",
      "Epoch [5/10], Step [200/600], Loss: 0.1198\n",
      "Epoch [5/10], Step [300/600], Loss: 0.1815\n",
      "Epoch [5/10], Step [400/600], Loss: 0.0595\n",
      "Epoch [5/10], Step [500/600], Loss: 0.0639\n",
      "Epoch [5/10], Step [600/600], Loss: 0.0446\n",
      "Epoch [6/10], Step [100/600], Loss: 0.0895\n",
      "Epoch [6/10], Step [200/600], Loss: 0.0330\n",
      "Epoch [6/10], Step [300/600], Loss: 0.0479\n",
      "Epoch [6/10], Step [400/600], Loss: 0.0593\n",
      "Epoch [6/10], Step [500/600], Loss: 0.0707\n",
      "Epoch [6/10], Step [600/600], Loss: 0.0471\n",
      "Epoch [7/10], Step [100/600], Loss: 0.0837\n",
      "Epoch [7/10], Step [200/600], Loss: 0.0326\n",
      "Epoch [7/10], Step [300/600], Loss: 0.0680\n",
      "Epoch [7/10], Step [400/600], Loss: 0.0952\n",
      "Epoch [7/10], Step [500/600], Loss: 0.0327\n",
      "Epoch [7/10], Step [600/600], Loss: 0.0257\n",
      "Epoch [8/10], Step [100/600], Loss: 0.0221\n",
      "Epoch [8/10], Step [200/600], Loss: 0.0756\n",
      "Epoch [8/10], Step [300/600], Loss: 0.0538\n",
      "Epoch [8/10], Step [400/600], Loss: 0.0847\n",
      "Epoch [8/10], Step [500/600], Loss: 0.0851\n",
      "Epoch [8/10], Step [600/600], Loss: 0.0470\n",
      "Epoch [9/10], Step [100/600], Loss: 0.0560\n",
      "Epoch [9/10], Step [200/600], Loss: 0.0630\n",
      "Epoch [9/10], Step [300/600], Loss: 0.0294\n",
      "Epoch [9/10], Step [400/600], Loss: 0.0509\n",
      "Epoch [9/10], Step [500/600], Loss: 0.0571\n",
      "Epoch [9/10], Step [600/600], Loss: 0.0275\n",
      "Epoch [10/10], Step [100/600], Loss: 0.0226\n",
      "Epoch [10/10], Step [200/600], Loss: 0.0434\n",
      "Epoch [10/10], Step [300/600], Loss: 0.0538\n",
      "Epoch [10/10], Step [400/600], Loss: 0.0235\n",
      "Epoch [10/10], Step [500/600], Loss: 0.0394\n",
      "Epoch [10/10], Step [600/600], Loss: 0.0553\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = torch.FloatTensor(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = torch.LongTensor(labels)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        losses.append(loss.cpu().item())\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f62bc3286d8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the FNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to training the nerual network, we also need to load batches of test images and collect the outputs. The differences are that:\n",
    "(1) No loss & weights calculation\n",
    "(2) No wights update\n",
    "(3) Has correct prediction calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = torch.FloatTensor(images.view(-1, 28*28))\n",
    "    \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained FNN Model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(), 'fnn_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
