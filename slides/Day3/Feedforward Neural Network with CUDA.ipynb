{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784       # The image size = 28 x 28 = 784\n",
    "hidden_size = 100      # The number of nodes at the hidden layer\n",
    "num_classes = 10       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 100       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the loading process of train_dataset to make the learning process independent of data orderness, but the order of test_loader remains to examine whether we can handle unspecified bias order of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4, \n",
    "                                          pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=4, \n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]\n",
      " - Numpy Shape: (60000, 28, 28)\n",
      " - Tensor Shape: torch.Size([60000, 28, 28])\n",
      " - min: tensor(0.)\n",
      " - max: tensor(1.)\n",
      " - mean: tensor(0.1307)\n",
      " - std: tensor(0.3081)\n",
      " - var: tensor(0.0949)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset.train_data\n",
    "train_data = train_dataset.transform(train_data.numpy())\n",
    "\n",
    "print('[Train]')\n",
    "print(' - Numpy Shape:', train_dataset.train_data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', train_dataset.train_data.size())\n",
    "print(' - min:', torch.min(train_data))\n",
    "print(' - max:', torch.max(train_data))\n",
    "print(' - mean:', torch.mean(train_data))\n",
    "print(' - std:', torch.std(train_data))\n",
    "print(' - var:', torch.var(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 0.4497\n",
      "Epoch [1/10], Step [200/600], Loss: 0.5651\n",
      "Epoch [1/10], Step [300/600], Loss: 0.1754\n",
      "Epoch [1/10], Step [400/600], Loss: 0.2538\n",
      "Epoch [1/10], Step [500/600], Loss: 0.1701\n",
      "Epoch [1/10], Step [600/600], Loss: 0.1523\n",
      "Epoch [2/10], Step [100/600], Loss: 0.1072\n",
      "Epoch [2/10], Step [200/600], Loss: 0.1339\n",
      "Epoch [2/10], Step [300/600], Loss: 0.1453\n",
      "Epoch [2/10], Step [400/600], Loss: 0.1364\n",
      "Epoch [2/10], Step [500/600], Loss: 0.1788\n",
      "Epoch [2/10], Step [600/600], Loss: 0.1014\n",
      "Epoch [3/10], Step [100/600], Loss: 0.1475\n",
      "Epoch [3/10], Step [200/600], Loss: 0.0875\n",
      "Epoch [3/10], Step [300/600], Loss: 0.0437\n",
      "Epoch [3/10], Step [400/600], Loss: 0.1095\n",
      "Epoch [3/10], Step [500/600], Loss: 0.0673\n",
      "Epoch [3/10], Step [600/600], Loss: 0.0822\n",
      "Epoch [4/10], Step [100/600], Loss: 0.0695\n",
      "Epoch [4/10], Step [200/600], Loss: 0.0507\n",
      "Epoch [4/10], Step [300/600], Loss: 0.0732\n",
      "Epoch [4/10], Step [400/600], Loss: 0.0801\n",
      "Epoch [4/10], Step [500/600], Loss: 0.0750\n",
      "Epoch [4/10], Step [600/600], Loss: 0.0446\n",
      "Epoch [5/10], Step [100/600], Loss: 0.1734\n",
      "Epoch [5/10], Step [200/600], Loss: 0.0275\n",
      "Epoch [5/10], Step [300/600], Loss: 0.0943\n",
      "Epoch [5/10], Step [400/600], Loss: 0.0444\n",
      "Epoch [5/10], Step [500/600], Loss: 0.0501\n",
      "Epoch [5/10], Step [600/600], Loss: 0.0259\n",
      "Epoch [6/10], Step [100/600], Loss: 0.0431\n",
      "Epoch [6/10], Step [200/600], Loss: 0.1654\n",
      "Epoch [6/10], Step [300/600], Loss: 0.0289\n",
      "Epoch [6/10], Step [400/600], Loss: 0.1175\n",
      "Epoch [6/10], Step [500/600], Loss: 0.0655\n",
      "Epoch [6/10], Step [600/600], Loss: 0.0344\n",
      "Epoch [7/10], Step [100/600], Loss: 0.0297\n",
      "Epoch [7/10], Step [200/600], Loss: 0.0398\n",
      "Epoch [7/10], Step [300/600], Loss: 0.0106\n",
      "Epoch [7/10], Step [400/600], Loss: 0.0338\n",
      "Epoch [7/10], Step [500/600], Loss: 0.0178\n",
      "Epoch [7/10], Step [600/600], Loss: 0.1571\n",
      "Epoch [8/10], Step [100/600], Loss: 0.0097\n",
      "Epoch [8/10], Step [200/600], Loss: 0.0110\n",
      "Epoch [8/10], Step [300/600], Loss: 0.0606\n",
      "Epoch [8/10], Step [400/600], Loss: 0.1127\n",
      "Epoch [8/10], Step [500/600], Loss: 0.0294\n",
      "Epoch [8/10], Step [600/600], Loss: 0.0532\n",
      "Epoch [9/10], Step [100/600], Loss: 0.0471\n",
      "Epoch [9/10], Step [200/600], Loss: 0.0463\n",
      "Epoch [9/10], Step [300/600], Loss: 0.0041\n",
      "Epoch [9/10], Step [400/600], Loss: 0.0143\n",
      "Epoch [9/10], Step [500/600], Loss: 0.0137\n",
      "Epoch [9/10], Step [600/600], Loss: 0.1339\n",
      "Epoch [10/10], Step [100/600], Loss: 0.0428\n",
      "Epoch [10/10], Step [200/600], Loss: 0.0035\n",
      "Epoch [10/10], Step [300/600], Loss: 0.0258\n",
      "Epoch [10/10], Step [400/600], Loss: 0.0349\n",
      "Epoch [10/10], Step [500/600], Loss: 0.0075\n",
      "Epoch [10/10], Step [600/600], Loss: 0.0500\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = torch.FloatTensor(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = torch.LongTensor(labels)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        losses.append(loss.cpu().item())\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f208dc21da0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the FNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to training the nerual network, we also need to load batches of test images and collect the outputs. The differences are that:\n",
    "(1) No loss & weights calculation\n",
    "(2) No wights update\n",
    "(3) Has correct prediction calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = torch.FloatTensor(images.view(-1, 28*28))\n",
    "    \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained FNN Model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(), 'fnn_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
