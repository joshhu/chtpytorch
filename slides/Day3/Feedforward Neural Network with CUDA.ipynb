{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784       # The image size = 28 x 28 = 784\n",
    "hidden_size = 100      # The number of nodes at the hidden layer\n",
    "num_classes = 10       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 100       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the loading process of train_dataset to make the learning process independent of data orderness, but the order of test_loader remains to examine whether we can handle unspecified bias order of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4, \n",
    "                                          pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=4, \n",
    "                                          pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]\n",
      " - Numpy Shape: (60000, 28, 28)\n",
      " - Tensor Shape: torch.Size([60000, 28, 28])\n",
      " - min: tensor(0.)\n",
      " - max: tensor(1.)\n",
      " - mean: tensor(0.1307)\n",
      " - std: tensor(0.3081)\n",
      " - var: tensor(0.0949)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_dataset.train_data\n",
    "train_data = train_dataset.transform(train_data.numpy())\n",
    "\n",
    "print('[Train]')\n",
    "print(' - Numpy Shape:', train_dataset.train_data.cpu().numpy().shape)\n",
    "print(' - Tensor Shape:', train_dataset.train_data.size())\n",
    "print(' - min:', torch.min(train_data))\n",
    "print(' - max:', torch.max(train_data))\n",
    "print(' - mean:', torch.mean(train_data))\n",
    "print(' - std:', torch.std(train_data))\n",
    "print(' - var:', torch.var(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward Neural Network Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "        \n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e70539abc69b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 0.3521\n",
      "Epoch [1/10], Step [200/600], Loss: 0.3184\n",
      "Epoch [1/10], Step [300/600], Loss: 0.2542\n",
      "Epoch [1/10], Step [400/600], Loss: 0.2150\n",
      "Epoch [1/10], Step [500/600], Loss: 0.1940\n",
      "Epoch [1/10], Step [600/600], Loss: 0.1987\n",
      "Epoch [2/10], Step [100/600], Loss: 0.2428\n",
      "Epoch [2/10], Step [200/600], Loss: 0.1298\n",
      "Epoch [2/10], Step [300/600], Loss: 0.3561\n",
      "Epoch [2/10], Step [400/600], Loss: 0.1399\n",
      "Epoch [2/10], Step [500/600], Loss: 0.2366\n",
      "Epoch [2/10], Step [600/600], Loss: 0.1867\n",
      "Epoch [3/10], Step [100/600], Loss: 0.1581\n",
      "Epoch [3/10], Step [200/600], Loss: 0.2705\n",
      "Epoch [3/10], Step [300/600], Loss: 0.1390\n",
      "Epoch [3/10], Step [400/600], Loss: 0.0770\n",
      "Epoch [3/10], Step [500/600], Loss: 0.0440\n",
      "Epoch [3/10], Step [600/600], Loss: 0.1469\n",
      "Epoch [4/10], Step [100/600], Loss: 0.0493\n",
      "Epoch [4/10], Step [200/600], Loss: 0.0939\n",
      "Epoch [4/10], Step [300/600], Loss: 0.1565\n",
      "Epoch [4/10], Step [400/600], Loss: 0.1321\n",
      "Epoch [4/10], Step [500/600], Loss: 0.1017\n",
      "Epoch [4/10], Step [600/600], Loss: 0.0656\n",
      "Epoch [5/10], Step [100/600], Loss: 0.0854\n",
      "Epoch [5/10], Step [200/600], Loss: 0.0471\n",
      "Epoch [5/10], Step [300/600], Loss: 0.1055\n",
      "Epoch [5/10], Step [400/600], Loss: 0.0680\n",
      "Epoch [5/10], Step [500/600], Loss: 0.0919\n",
      "Epoch [5/10], Step [600/600], Loss: 0.0518\n",
      "Epoch [6/10], Step [100/600], Loss: 0.1107\n",
      "Epoch [6/10], Step [200/600], Loss: 0.0789\n",
      "Epoch [6/10], Step [300/600], Loss: 0.0658\n",
      "Epoch [6/10], Step [400/600], Loss: 0.0424\n",
      "Epoch [6/10], Step [500/600], Loss: 0.0338\n",
      "Epoch [6/10], Step [600/600], Loss: 0.1638\n",
      "Epoch [7/10], Step [100/600], Loss: 0.0913\n",
      "Epoch [7/10], Step [200/600], Loss: 0.0425\n",
      "Epoch [7/10], Step [300/600], Loss: 0.0090\n",
      "Epoch [7/10], Step [400/600], Loss: 0.0719\n",
      "Epoch [7/10], Step [500/600], Loss: 0.1647\n",
      "Epoch [7/10], Step [600/600], Loss: 0.0436\n",
      "Epoch [8/10], Step [100/600], Loss: 0.0296\n",
      "Epoch [8/10], Step [200/600], Loss: 0.0334\n",
      "Epoch [8/10], Step [300/600], Loss: 0.0409\n",
      "Epoch [8/10], Step [400/600], Loss: 0.0776\n",
      "Epoch [8/10], Step [500/600], Loss: 0.0659\n",
      "Epoch [8/10], Step [600/600], Loss: 0.0598\n",
      "Epoch [9/10], Step [100/600], Loss: 0.0433\n",
      "Epoch [9/10], Step [200/600], Loss: 0.0480\n",
      "Epoch [9/10], Step [300/600], Loss: 0.0120\n",
      "Epoch [9/10], Step [400/600], Loss: 0.0463\n",
      "Epoch [9/10], Step [500/600], Loss: 0.0908\n",
      "Epoch [9/10], Step [600/600], Loss: 0.0781\n",
      "Epoch [10/10], Step [100/600], Loss: 0.0154\n",
      "Epoch [10/10], Step [200/600], Loss: 0.0166\n",
      "Epoch [10/10], Step [300/600], Loss: 0.0425\n",
      "Epoch [10/10], Step [400/600], Loss: 0.0232\n",
      "Epoch [10/10], Step [500/600], Loss: 0.0663\n",
      "Epoch [10/10], Step [600/600], Loss: 0.0366\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = torch.FloatTensor(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = torch.LongTensor(labels)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        losses.append(loss.cpu().item())\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9df597b6d8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNX9//HXJ+wIsqaKCAYUt9ZWkeLeWpe6tfqzy7f666O1Vr920dZ+/X21sX7r1lrRn7WtWrdapWoVN1pRUFRAUZAlQNgFAgQIBJJAFkLIOuf7x9wZJpk16+QO7+fjkcfM3Lm5cw5M3nPm3HPPMeccIiKSWbLSXQAREel4CncRkQykcBcRyUAKdxGRDKRwFxHJQAp3EZEMpHAXEclACncRkQykcBcRyUA90/XCw4cPdzk5Oel6eRERX1qyZEmZcy472X5pC/ecnBzy8vLS9fIiIr5kZltS2U/dMiIiGUjhLiKSgRTuIiIZSOEuIpKBFO4iIhlI4S4ikoEU7iIiGch34b5u517++N46yqrr0l0UEZFuy3fhvqFkL4/OLmDPvvp0F0VEpNvyXbgbBoDW9RYRic934Z4VzHYcSncRkXh8F+7mhXsgkN5yiIh0Z74Ld0LdMmq5i4jE5btwD7Xc1ecuIhKf/8I93QUQEfEB34V7lmm0jIhIMr4L9/AJVaW7iEhcvg13RbuISHz+C/fwRUyKdxGReHwX7qjlLiKSlO/CPTRaRg13EZH4fBfuodEyaruLiMTnu3A/MFomveUQEenO/BfumhVSRCQp/4V7ePoBpbuISDz+C3fvVtEuIhKf/8Jd0w+IiCTlw3AP3qpbRkQkPv+Fu3eraBcRic9/4a5uGRGRpHwY7sFbrcQkIhJf0nA3s1FmNsfM1prZajO7OcY+ZmaPmFmBma0ws/GdU9yIBbKV7SIicfVMYZ9G4P8555aa2UBgiZm975xbE7HPJcA47+c04AnvthME013zuYuIxJe05e6cK3bOLfXu7wXWAiNb7HYF8LwLWgAMNrMRHV5aNJ+7iEgqWtXnbmY5wCnAwhZPjQS2RTwuIvoDoEOE11BVuouIxJVyuJvZAOAN4FfOuaqWT8f4laj4NbMbzCzPzPJKS0tbV9IDx/AOrnQXEYknpXA3s14Eg/2fzrmpMXYpAkZFPD4S2NFyJ+fc0865Cc65CdnZ2W0pr+ZzFxFJQSqjZQz4O7DWOfdwnN2mAT/0Rs2cDlQ654o7sJxhWRrnLiKSVCqjZc4CfgCsNLN8b9tvgNEAzrkngRnApUABUANc2/FFDTown7vSXUQknqTh7pz7hNh96pH7OODGjipUKhTtIiLx+fcKVaW7iEhc/gt3TR0mIpKU78I9yyuxWu4iIvH5LtwtPP1AmgsiItKN+S/cNSukiEhS/gt371bdMiIi8fkv3DVxmIhIUr4L91DbXWuoiojE57twz0p4OZWIiIAPwz00K6SmHxARic9/4e7dKttFROLzX7hr+gERkaT8F+6hE6ppLoeISHfmv3APt9wV7yIi8fg43NNbDhGR7syH4a41VEVEkvFfuHu3armLiMTnv3DX9AMiIkn5L9zRAtkiIsn4LtyzNOWviEhSvgv3UKe7FusQEYnPd+EeXkNV/TIiInH5L9x1QlVEJCn/hbt3q4a7iEh8vgv3LNNiHSIiyfgu3E0nVEVEkvJfuGtWSBGRpHwX7mhWSBGRpHwX7qY1VEVEkvJfuHu3ariLiMTnu3DP0pS/IiJJ+S7cNVpGRCQ5/4W7ZoUUEUnKf+GuWSFFRJJKGu5m9qyZlZjZqjjPn2tmlWaW7/3c2fHFjKaWu4hIfD1T2Gcy8BjwfIJ9PnbOfaNDSpRElsZCiogklbTl7pybC+zpgrKkJHxCVWdURUTi6qg+9zPMbLmZvWNmn4+3k5ndYGZ5ZpZXWlraphcKj3Nv02+LiBwcOiLclwJHOee+BDwK/Dvejs65p51zE5xzE7Kzs9v0YmYaLSMikky7w905V+Wcq/buzwB6mdnwdpcsjgMtd6W7iEg87Q53MzvcvOa0mU30jrm7vceN/3rBW7XcRUTiSzpaxsxeBs4FhptZEXAX0AvAOfck8B3gZ2bWCOwHrnKdOGWjabEOEZGkkoa7c+7qJM8/RnCoZJcx0wlVEZFEfHeFKgT73dVwFxGJz5/hbqYTqiIiCfgy3LNMs0KKiCTiy3A3M3XLiIgk4M9wR6NlREQS8WW4Z5mpx11EJAGfhrsmDhMRScSn4W46oSoikoAvw90MAupzFxGJy6fhbjqhKiKSgC/DPUvTD4iIJOTTcDd1y4iIJODLcDedUBURScin4a6LmEREEvFluAfHuae7FCIi3ZdPw12zQoqIJOLbcFefu4hIfL4Md13EJCKSmG/DXdkuIhKfL8M9S1eoiogk5NtwV5+7iEh8vgx39bmLiCTmy3DP0jJ7IiIJ+TLcDbXcRUQS8WW4q+UuIpKYL8Ndfe4iIon5Mtw1WkZEJDFfhrtmhRQRScyX4R6cOExEROLxabirz11EJBFfhrtWYhIRScyX4Z6lPncRkYR8Ge6mBbJFRBLyZbhnacpfEZGEkoa7mT1rZiVmtirO82Zmj5hZgZmtMLPxHV/MqNdUy11EJIFUWu6TgYsTPH8JMM77uQF4ov3FSiw4WqazX0VExL+Shrtzbi6wJ8EuVwDPu6AFwGAzG9FRBYxFi3WIiCTWEX3uI4FtEY+LvG1RzOwGM8szs7zS0tI2v6Cp5S4iklBHhLvF2BYzep1zTzvnJjjnJmRnZ7f5BdVyFxFJrCPCvQgYFfH4SGBHBxw3Ll3EJCKSWEeE+zTgh96omdOBSudccQccNy5dxCQikljPZDuY2cvAucBwMysC7gJ6ATjnngRmAJcCBUANcG1nFTZcJtTnLiKSSNJwd85dneR5B9zYYSVKQXBWSKW7iEg8vrxC1cwIBNJdChGR7suX4a4pf0VEEvNpuGuBbBGRRHwZ7logW0QkMV+Gu5bZExFJzJfhrpa7iEhivgx39bmLiCTmy3BfvaOSzWX70l0MEZFuy5fhvrFUwS4ikogvw11ERBJTuIuIZCCFu4hIBlK4i4hkIIW7iEgG8nW4ry2uSncRRES6JV+H+yuLtyXfSUTkIOTrcBcRkdh8He5aR1VEJDZfh7vWURURic3X4b68qCLdRRAR6ZZ8He5NarqLiMSkcBcRyUC+DvfPdu5NdxFERLolX4e7iIjE5stwH3ZI73QXQUSkW/NluJtZ+P77a3ZRqFWZRESa6ZnuArRF1oFs5z+fzwOgcNJlaSqNiEj348uWu4iIJObLcB89tH+6iyAi0q35Mtx/cMZR6S6CiEi35stwH9DHl6cKRES6jC/DPWKwjIiIxODPcEfpLiKSSErhbmYXm9k6Mysws9wYz//IzErNLN/7ub7jixr5gp16dBER30vaeW1mPYC/AhcCRcBiM5vmnFvTYtdXnHM3dUIZo2TF6JepbWiib68eXfHyIiLdXiot94lAgXNuk3OuHpgCXNG5xUosK0bL/bJHPu76goiIdFOphPtIIHIl6iJvW0vfNrMVZva6mY3qkNLFEavPfWNp8ykIAgHHT17IY8Gm3Z1ZFBGRbimVcI/Vw91yIvW3gBzn3BeBD4B/xDyQ2Q1mlmdmeaWlpa0rabPjJN+nqraBmat3cYM3PUFByV6tuSoiB41Uwr0IiGyJHwnsiNzBObfbOVfnPfwbcGqsAznnnnbOTXDOTcjOzm5LeQHo0zN2sc+4fxZjbp/ebJuZsXDTbi54eC4vLtjS5tcUEfGTVMJ9MTDOzMaYWW/gKmBa5A5mNiLi4eXA2o4rYrQvHjk45vbiylpCjfPQrRkU7g522azcXtmZxRIR6TaSjpZxzjWa2U3ATKAH8KxzbrWZ3QvkOeemAb80s8uBRmAP8KNOLHNK3TIBL901alJEDkYpXcfvnJsBzGix7c6I+7cDt3ds0RKVJ/V9rZ2Xs5bvq6dXzyxNeSAivuLLK1RjDYWM5JwLn/G1Zttb/1qn/O59zn5gdut/UUQkjXwZ7j17JC52/raKZn3u7VVR09D+g4iIdCFfhnsyTQFHbUMTEGytBzQCUkQOMhkZ7g4458E5AOzeV8/tU1emt0AiIl0sI8NdRORgl5HhrgtRReRgl5Hh3hZNAUdNfWO6iyEi0iEyMtxvn7oi5vZEDfpbX1vOiXfO7JwCiYh0sYwM95YzREZ6fUkR2/bURG2fumx7ZxZJRKRLZWS4xxMIOP77teV898lPU9q/sSnQptepqKnnvdU72/S7IiIdwbfhfuUpsaaUTyzUOt9ZVUtO7vTwFMCFZbFb+uP+5502le1nLy7lhheWULK3tk2/LyLSXr4N995JrlJNRaN3ddO5D30Y3hY553vkqJvQydYXFmzh1bzItUuihWahbGjSsB0RSQ/fhntHcI6oBTziDaMMnWz97b9XcdvrsU/YtjyGZqQUkXQ5qMM94FzU1AR//mA9AN99cn6rjvXorA1cN3kxAKFpy9oyr03uGyv43dst1x4XEWkd34Z7R0wIdvxv3+WDtbuabXtkdgF/m7uJxYXlCX+3sSnAw++tY29tcFKxP76/nlmflQAHWu5ZbSjklMXb+Psnm1v9eyIikXwb7h3l6bmborbdNyP5QlJvrdjBI7MLePDddVHPxZpuWESkK/k23H9x/jjOPHpYu4+zOc5ImWRCLfv6xujhkk7pLiJp5ttwHzm4Hy/95+ntPs6effVt+r2XFm4FICvGv6ALL/HXNem+u7ou6sSwiBzcfBvu3cX7a3aF544PCcVsRU092yv2U9fYxJRFW8MfCBD8AGhI4SKp2oYmcnKnM2XR1pjPbyyt5tTff8Dk+YVU1zVS19gUcz8RObgo3NuprLqebz/RfGRNqBV94Z/mctak2Vzx2Dxyp67kN/86MK/8b99cxbg7kl8kVVZdB8CjswtiPr/FG1M/d30pX7hrJt945JM21aOzLNlSTk7udIor96e7KCIHFd+H++cG9kl3EZpd4bqvrjFqgrLPdu6N+p0XFwRb4ql2p6S634aS6pT26yovLtgCwPyC3WkuicjBxffhfutFx3XZa+XkTo+5PXKs/OfvmtmqNVdL9tZRVB49kVmIecMpW9OjHrqadsqireyqSu8UCKHRoC3LP3d9KTm50xPWXUTazvfh/t0Joxg1tF9ayxBox8nM0/4wi7MfmENO7vRmHx6h0GvLKdncN1by7qpicqeu5Lp/BC+sCgQcD7z7Gdsr9lNZ08Cb+fFnwVy4aTc5udMpKIn+xtFaoZPKLf+NXlkcnMLh5in5UecsRKT9fB/uAB/fdh4njRyUttevizEcsr3OfmAOVz4+jzMnzQaC4Thz9U4CKaz2vamsmp++uBSAPdXB0UBriqt44sON/OKlpfzXq/ncPCWfjaUHunB2VdXyzspiiiv388RHGwGYv7H9XSnh67gcNDQFmP3ZrnB9INgn/1ic8wki0nY9012AjvLCdRMpKKlmY2k1v36j+y6Ifcq979G/d2r/7Mu2VoTv76qq4ycvLOGOS0/g0dkbuO/Kk/jml46I+XuRQzBD3TpN3odCWXU99d4onZq6YIu5pKqWrz30ITX1rW9BX/X0p2ws3cfiOy4AgucGpi3fwcVfOJw+PXuQFe6WcTw6awOPzC7g+R9PbNaSr6pNvRuro23bU0NtQxPjDhuYtjKIdIaMaLkDDO7fmwk5Qznv+MPSXZSEymsa2F7R9pEjK7ZXUlXbyH3Tm19FO2ddacLfC0Xp1j01rNpeBcDqHZUATPzDrJjBnr+tgpzc6ZQnuBZgwaY9lO6tCz+eu6GMm6fk89DM4JW7oQ+au6et4ZOCMiA4AijyC0g6h+if8+AcLvzT3PQVQKSTZEy4h2QP7MP/XHZCuovRad5avgMIzkl/3kMf8uPJeVH7rNxeGbVtw67o/vPcqYm/4UxdGuyXf3DmZymXr2p/sBW+ozJ4IjfULbO/oYml3jeRWLNxdobqutTXxK2pb2RHxX4amgK8tHBrSt1fu6vreGz2BjaWVrNmR1V7iirS4TIu3AGumjgaIKNDHmBTClMnmMHkeZu5Nc40xfM3liU9xsuLms9f/+6qYuasK+Hh99fHfD2IuEo3xuRpCzfvpj5irvuPNwS/dfxjfiFLtuxJWp5UvL6kiC/cNTPmh1osVz+9gDMnzeZL97zHb/61kteXFiX9nV+/sZKH3lvP+X/8iEsf+bjVZVyypZy/fLCh1b8nkoqMDPcBfXpSOOkyrjt7DDd+7eh0Fyetisr3c/db8acQ/r9/W5jScW56aWn4/k9fXMq1zy3mkVkHgqmusYmbXlrK9vJgl1N4TvsYw31ezSti7voD3UiFu2t4ccEW7pq2mm8/8WnC4Zv1jQHunraa3dV1cfcBwiduV++oinklsHOOqREBvrwo+G0n1D0V+gaSSGjIaaSi8pqUZ/X89hPz+dMH0R+QftEUcNz71pqUh9sGAq5dXZLtcf87a5nmfes9WGRkuIeYGbdedHz48ep7Lkpjafzt7RXFUcM1I328voy3VxRz/zvBLpx3Vu0kJ3c6JSn+4f/Pv1eF75/2h1nMWFkcc793V+9k8vxC7pu+lsamAM98vImSqtqooA319f/qlXy+fN8H4e3b9tSwZfc+pi3fwS2vLk+pbACLNu9JqZvnusl5/O7tNc3qfc9bq7noT3PZWFpNSVUtFTX1rCiqSHCUaCuLKplfkPxbVshredv4WsQKYy0t3Vre7m9J8zeW8ey8zeS+kXjxGoDKmgYe/7CAsybNZlNp119o99RHm/jly8u6/HXTKWNGy6TikD4HVXW71PXPR/f9A3ywtqRNx/v5P5ey9t6Lmbl6J1ecfARV+xuZvW4XAa8RvqemnpcXbeX309fye+/kcuGkyyJe98A8/RU1DeytbWBz2T4uf2weAMceNiDlspTvq+c/nvqUc4/LZvK1E8Pb99ZGh33oA6A+4tvCc/MKATj/jx8BcMKIQ1lbfKCP/vQ/zOLpH57KF48cHN62uHAPf/lgA5Ov/TI9e2Txzcc+iapjIpHdcM45dlXVcfigvuFt33p8fquOF0votERjkvMTpXvrmn3A7qioZWx26v/+ne3Xr69g9LD+3Pi1Y9p9rLzCPXxh5CD69urRASVrn4xuuYesvPvrrLz76+kuhrTSNc8t4lev5LNo8x5ueTWf/3plOeu9PvQP15VSVt18FE9ReQ3rd+3l+U8Lo649OOnu98LBDrB+V/LWY/62CpZuLafGu8hqbXEVry7eRk7udKpqG6JOXNc2NIW7Hcr3NTDujhl8uC76wy0y2CF4cvzyx+aRkzudyx/7hDmflfCrKfl8UlDGB2tLmp2sneiFZEHJ3vAHyat528Kt8MamAM/NO9At5JzjtSVFnH7/LO55azVwYFhse7XscQsEoifDezN/O6tinOAP7d+RF7D9x1OfcuKd70Zt3xHRFfT9ZxY0u74D4JW8bfz/mdHrMrS0bU8NFTXxR44Vlu3jO09+yp1vroq7T1c6KJqyA/v2Ct9/6frTGNS/FxtL94W/pv383KM5bewwRg7ux0V/ntthb35pn0Wbg4H1vacXhLctLjzQlfCXWc1PRp79wJwOe23n4P/8dV6zbbuq6rjN64LYWRnd3RRqoUNw/H9Dk4s74Vs8K4oquXbyYkYODl51/dMXlzR7vmRvHfvqGrng4bmMHz2YqT8/K7ymb+Gky5iyeBv3RJxjCbgD/47PzSvk3OM+x9HZh4Sfn7q0iG+NP7JVZZyxspgsM/r3DrZOG5scdY1N/GbqKt5YWhT+NnDeQx/GPOl/34y13PS1Y3jmk00s21rBZ7+7OOWW7pzPSjhhxKHNvoWEhOq5ZEs5px41JLw9dCEgwLyC3Zz/x4949OpTGJt9CIP6HciG4sr9OAdHDI59xfs5D85h6CG9WfrbC2M+H/q2+GpeEdkD+/CjM8fQGAgwYlB6rqC3dM0DPmHCBJeXF/urfFcJ9R9HfjW9+ukFfLppN189NpuTRw2OChARCI7E+v305Ct2tdXIwf3innyMfO0v5wwJLxzz92smcN0/mv9N/eSrY3nqo+arjR1/+MCoyeye+eEELjgxeI3I/vom1hRXcXT2IQzu3xsInlCfcNQQfnTWmPDfzV+uOpmbp+RHlS/09xTv/ExL+XdeGH6dcHk+3sT2iv3c9c3Ps2xrOcu2VvDjs4OvPWJQXz69/fyo40S+3ps3nsWXRg2moqaek+99P6VyRJb/w3Ul7K1t5OjsAZx4xKHNjl846TJ2V9dR1xjgiMH9mL+xLOHAhJNGDuIX5x1D9sA+fLZzL8cdPpDxo4fE3T8ZM1vinJuQbL+UWu5mdjHwF6AH8IxzblKL5/sAzwOnAruB7znnCltb6K72+k/PYFFh85NKj39/PAs27eaSk0YAwVbAsq3l/PvGs1heVMl/v9b8JNx1Z4+JOTrizKOHdcjl+9I9dWawAwlHlUS+duRavy2DHYgKdog9S+n1z+dROOkylm0t58rHD0xh/e3xR/KGN6ro7RXFnDb2wOpnn2yIfYL3ysfncUwr+tQv/vPHPPy9L3Hm0cNpaAo0mwr7whMPCwdnKGSLK2v529xNTMgZwimjh3DLK/mcmtM8LG95NZ+fnXtM1N9rKkr21vKj5xaHH9960XHURXQfVdU2cOrvg91j83PP445/Je6GWbm9khteaP4N7J2bz+GEEYe2umytkbTlbmY9gPXAhUARsBi42jm3JmKfnwNfdM791MyuAq50zn0v0XG7Q8u9LWasLOat5Ts4Z1w2l3zhcA7t14tzHpjNC9efhnOOaycv5vqzx/L900ZzzB3vNGtlRLYs7v7miQmHKIocbE49agg9zKIaXJmqrSezO7LlPhEocM5t8g48BbgCiEymK4C7vfuvA4+ZmbkMXPvt0pNGcKnXqg+ZH/EV8ePbzgvfj/Wfd8rowbz2kzPo2SOLxoALt8JOHzuUp34wgWVby5k4ZigLNu1m6ZYKbr5gHE98uDF8wdBXjs1uNka8I0W20iBx14BIR1uypTz5TpKyVFru3wEuds5d7z3+AXCac+6miH1WefsUeY83evvEHZjr15Z7e9Q1NtEzK4seWe1bW3VjaTUriirYVVXHwL496dUji68em82tr6/AOccFJxzGRZ8/nFXbK+nfpwdHDTuETaXVfP6IQVTU1LNkSzlHDO7HW8t3MMWbenfz/ZdiZuyvb+KEO9/ll+eP45YLj6WwbB/neuOlbz5/XNQ5iNxLjmfSO7GnJzhtzFAWbt7DT74yllfytkXNc//ri4/ngXdTn9pAJFMM7t+L/DvbNoIv1ZZ7KuH+XeCiFuE+0Tn3i4h9Vnv7RIb7ROfc7hbHugG4AWD06NGnbtmypXW1ki7R0BSgZ5bFnDqgsSkQ/nAKOJp9UDnnMDMCAYeDlD/EahuaKK+pp7HJkT2wT3jkRMneWob2742ZkWUweX4hxx42kH11jRzzuQF87tC+rCiqYGLOUEr21lFR08C8gjLGHzWEvr2yCASC/bTOBa+M7JFl9OvVg2ED+hAIOPbVNzKwby82l+1j2IDevLV8B2OHD2DEoL6UVtexensla4v3MmpoP1Ztr+LMY4YxsG9Phg/ow/trdrG/volfnj+O6rpGhvTvzR9mrKVvryy+c+ooGpoCDB/Qh7umrWJHRS019U1kD+zDbRcdx66qWg4f1JfePbIYckhvdlbV0isri721DazeUcVjc4IjbH553jE0BhwTxwxlRVEl8wrKWOiNCOnfuweD+/Vi9LD+HNq3F++tCY7UCJ3rOWfccDbsquarx2aTt2UPm8r2cdbRw7nkpMN5La+I/G3Bi6i+dcpIVmyvpKATV/D61ikjmbosOE9R5Bj/o4b1Z8vuzl2sJWdYfwo7+TXaYvmdX2dQ/17Jd4yhI8P9DOBu59xF3uPbAZxz90fsM9Pb51Mz6wnsBLITdcscjC13EZH2SjXcU7mIaTEwzszGmFlv4CpgWot9pgHXePe/A8zOxP52ERG/SHpC1TnXaGY3ATMJDoV81jm32szuBfKcc9OAvwMvmFkBsIfgB4CIiKRJSuPcnXMzgBkttt0Zcb8W+G7HFk1ERNrqoJhbRkTkYKNwFxHJQAp3EZEMpHAXEclACncRkQyUtil/zawUaOslqsOB1Ncc695Ul+4pU+qSKfUA1SXkKOdcdrKd0hbu7WFmealcoeUHqkv3lCl1yZR6gOrSWuqWERHJQAp3EZEM5NdwfzrdBehAqkv3lCl1yZR6gOrSKr7scxcRkcT82nIXEZEEfBfuZnaxma0zswIzy013eWIxs2fNrMRboSq0baiZvW9mG7zbId52M7NHvPqsMLPxEb9zjbf/BjO7JtZrdXI9RpnZHDNba2arzexmH9elr5ktMrPlXl3u8baPMbOFXrle8aa1xsz6eI8LvOdzIo51u7d9nZld1NV18crQw8yWmdnbPq9HoZmtNLN8M8vztvnu/eWVYbCZvW5mn3l/M2ektS7OOd/8EJxyeCMwFugNLAdOTHe5YpTzK8B4YFXEtgeBXO9+LvCAd/9S4B3AgNOBhd72ocAm73aId39IF9djBDDeuz+Q4ELpJ/q0LgYM8O73AhZ6ZXwVuMrb/iTwM+/+z4EnvftXAa9490/03nd9gDHe+7FHGt5jtwAvAW97j/1aj0JgeIttvnt/eeX4B3C9d783MDiddenSynfAP94ZwMyIx7cDt6e7XHHKmkPzcF8HjPDujwDWefefAq5uuR9wNfBUxPZm+6WpTm8CF/q9LkB/YClwGsELSXq2fH8RXL/gDO9+T28/a/mei9yvC8t/JDALOA942yuX7+rhvW4h0eHuu/cXcCiwGe88Zneoi9+6ZUYC2yIeF3nb/OAw51wxgHf7OW97vDp1q7p6X+dPIdji9WVdvK6MfKAEeJ9ga7XCOdcYo1zhMnvPVwLD6B51+TNwGxDwHg/Dn/UAcMB7ZrbEgmssgz/fX2OBUuA5r7vsGTM7hDTWxW/hHmvFZb8P94lXp25TVzMbALwB/Mo5V5Vo1xjbuk1dnHNNzrmTCbZ8JwInxNrNu+2WdTGzbwAlzrklkZtj7Nqt6xHhLOfceOAS4EYz+0qCfbtzXXqIKp2dAAAB40lEQVQS7Ip9wjl3CrCPYDdMPJ1eF7+FexEwKuLxkcCONJWltXaZ2QgA77bE2x6vTt2irmbWi2Cw/9M5N9Xb7Mu6hDjnKoAPCfZ1Drbgou4tyxUus/f8IIJLSKa7LmcBl5tZITCFYNfMn/FfPQBwzu3wbkuAfxH80PXj+6sIKHLOLfQev04w7NNWF7+FeyqLdXdXkYuIX0Ow/zq0/Yfe2fPTgUrv69tM4OtmNsQ7w/51b1uXMTMjuD7uWufcwxFP+bEu2WY22LvfD7gAWAvMIbioO0TXJdai79OAq7xRKGOAccCirqkFOOdud84d6ZzLIfj+n+2c+z4+qweAmR1iZgND9wm+L1bhw/eXc24nsM3MjvM2nQ+sIZ116eoTKB1w4uJSgqM2NgJ3pLs8ccr4MlAMNBD8JL6OYD/nLGCDdzvU29eAv3r1WQlMiDjOj4EC7+faNNTjbIJfCVcA+d7PpT6tyxeBZV5dVgF3etvHEgy1AuA1oI+3va/3uMB7fmzEse7w6rgOuCSN77NzOTBaxnf18Mq83PtZHfp79uP7yyvDyUCe9x77N8HRLmmri65QFRHJQH7rlhERkRQo3EVEMpDCXUQkAyncRUQykMJdRCQDKdxFRDKQwl1EJAMp3EVEMtD/Aq4TXq61WFuRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the FNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to training the nerual network, we also need to load batches of test images and collect the outputs. The differences are that:\n",
    "(1) No loss & weights calculation\n",
    "(2) No wights update\n",
    "(3) Has correct prediction calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = torch.FloatTensor(images.view(-1, 28*28))\n",
    "    \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained FNN Model for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(net.state_dict(), 'fnn_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
