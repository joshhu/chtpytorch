{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight= Parameter containing:\n",
      "tensor([[0.6962, 0.6027]], requires_grad=True)\n",
      "bias= Parameter containing:\n",
      "tensor([-0.4255], requires_grad=True)\n",
      "input= <class 'torch.Tensor'>\n",
      "torch.Size([1, 1])\n",
      "tensor([[0.8735]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "m = torch.nn.Linear(3, 1, bias=True)\n",
    "print(\"weight=\",m.weight)\n",
    "print(\"bias=\",m.bias)\n",
    "input = torch.ones(1,3)\n",
    "print(\"input=\",type(input))\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_data = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.tensor([[2.0], [4.0], [6.0]])\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear module\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)  # One in and one out, linear = y=wx + b\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight= Parameter containing:\n",
      "tensor([[-0.6438,  0.2346]], requires_grad=True)\n",
      "bias= Parameter containing:\n",
      "tensor([0.4305], requires_grad=True)\n",
      "input= <class 'torch.Tensor'>\n",
      "torch.Size([1, 1])\n",
      "tensor([[0.0214]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "m = torch.nn.Linear(2, 1, bias=True)\n",
    "print(\"weight=\",m.weight)\n",
    "print(\"bias=\",m.bias)\n",
    "input = torch.ones(1,2)\n",
    "print(\"input=\",type(input))\n",
    "output = m(input)\n",
    "print(output.size())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshhu/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 122.76983642578125\n",
      "1 54.78213119506836\n",
      "2 24.514087677001953\n",
      "3 11.037792205810547\n",
      "4 5.0367350578308105\n",
      "5 2.363467216491699\n",
      "6 1.1716625690460205\n",
      "7 0.6393868923187256\n",
      "8 0.4007396996021271\n",
      "9 0.29283198714256287\n",
      "10 0.2431502640247345\n",
      "11 0.2194121927022934\n",
      "12 0.20724734663963318\n",
      "13 0.20025712251663208\n",
      "14 0.19559288024902344\n",
      "15 0.19198688864707947\n",
      "16 0.18887385725975037\n",
      "17 0.1860019564628601\n",
      "18 0.18325844407081604\n",
      "19 0.1805938184261322\n",
      "20 0.17798464000225067\n",
      "21 0.17542025446891785\n",
      "22 0.17289644479751587\n",
      "23 0.17041048407554626\n",
      "24 0.16796082258224487\n",
      "25 0.16554665565490723\n",
      "26 0.16316749155521393\n",
      "27 0.16082239151000977\n",
      "28 0.15851102769374847\n",
      "29 0.15623320639133453\n",
      "30 0.15398764610290527\n",
      "31 0.15177477896213531\n",
      "32 0.1495935022830963\n",
      "33 0.14744354784488678\n",
      "34 0.14532460272312164\n",
      "35 0.14323602616786957\n",
      "36 0.1411776840686798\n",
      "37 0.13914865255355835\n",
      "38 0.13714876770973206\n",
      "39 0.13517771661281586\n",
      "40 0.13323503732681274\n",
      "41 0.13132010400295258\n",
      "42 0.12943291664123535\n",
      "43 0.12757273018360138\n",
      "44 0.12573941051959991\n",
      "45 0.12393225729465485\n",
      "46 0.12215118855237961\n",
      "47 0.12039555609226227\n",
      "48 0.11866529285907745\n",
      "49 0.11695992201566696\n",
      "50 0.1152791753411293\n",
      "51 0.11362242698669434\n",
      "52 0.11198944598436356\n",
      "53 0.11037985235452652\n",
      "54 0.10879363119602203\n",
      "55 0.10722998529672623\n",
      "56 0.10568900406360626\n",
      "57 0.10416992753744125\n",
      "58 0.10267297178506851\n",
      "59 0.10119742900133133\n",
      "60 0.09974304586648941\n",
      "61 0.09830959141254425\n",
      "62 0.09689664095640182\n",
      "63 0.09550410509109497\n",
      "64 0.09413169324398041\n",
      "65 0.09277872741222382\n",
      "66 0.09144549071788788\n",
      "67 0.0901312381029129\n",
      "68 0.08883592486381531\n",
      "69 0.08755908906459808\n",
      "70 0.08630084246397018\n",
      "71 0.08506056666374207\n",
      "72 0.08383794128894806\n",
      "73 0.08263314515352249\n",
      "74 0.08144565671682358\n",
      "75 0.08027498424053192\n",
      "76 0.07912135869264603\n",
      "77 0.07798430323600769\n",
      "78 0.076863594353199\n",
      "79 0.07575900852680206\n",
      "80 0.07467008382081985\n",
      "81 0.07359699159860611\n",
      "82 0.07253935188055038\n",
      "83 0.07149682193994522\n",
      "84 0.0704692155122757\n",
      "85 0.06945645809173584\n",
      "86 0.06845824420452118\n",
      "87 0.06747446209192276\n",
      "88 0.06650469452142715\n",
      "89 0.06554890424013138\n",
      "90 0.06460700184106827\n",
      "91 0.0636783316731453\n",
      "92 0.0627632886171341\n",
      "93 0.06186110898852348\n",
      "94 0.060972198843955994\n",
      "95 0.06009593605995178\n",
      "96 0.059232257306575775\n",
      "97 0.058380983769893646\n",
      "98 0.05754196271300316\n",
      "99 0.0567149855196476\n",
      "100 0.0558999627828598\n",
      "101 0.05509655177593231\n",
      "102 0.05430474504828453\n",
      "103 0.05352427810430527\n",
      "104 0.05275515094399452\n",
      "105 0.05199681222438812\n",
      "106 0.05124959722161293\n",
      "107 0.050513070076704025\n",
      "108 0.04978710412979126\n",
      "109 0.04907159134745598\n",
      "110 0.04836631193757057\n",
      "111 0.047671280801296234\n",
      "112 0.0469861663877964\n",
      "113 0.04631095379590988\n",
      "114 0.04564528912305832\n",
      "115 0.044989410787820816\n",
      "116 0.04434274882078171\n",
      "117 0.04370558261871338\n",
      "118 0.043077368289232254\n",
      "119 0.042458269745111465\n",
      "120 0.041848089545965195\n",
      "121 0.04124665632843971\n",
      "122 0.040653858333826065\n",
      "123 0.040069643408060074\n",
      "124 0.03949377313256264\n",
      "125 0.038926176726818085\n",
      "126 0.03836672008037567\n",
      "127 0.037815336138010025\n",
      "128 0.03727181628346443\n",
      "129 0.0367361456155777\n",
      "130 0.03620821237564087\n",
      "131 0.03568790853023529\n",
      "132 0.03517504036426544\n",
      "133 0.034669507294893265\n",
      "134 0.03417124226689339\n",
      "135 0.033680107444524765\n",
      "136 0.03319602459669113\n",
      "137 0.03271904215216637\n",
      "138 0.03224887326359749\n",
      "139 0.03178534284234047\n",
      "140 0.03132849186658859\n",
      "141 0.030878286808729172\n",
      "142 0.03043445385992527\n",
      "143 0.0299970880150795\n",
      "144 0.029566017910838127\n",
      "145 0.02914116345345974\n",
      "146 0.028722349554300308\n",
      "147 0.02830957993865013\n",
      "148 0.02790268324315548\n",
      "149 0.027501681819558144\n",
      "150 0.02710643596947193\n",
      "151 0.026716912165284157\n",
      "152 0.02633286640048027\n",
      "153 0.02595440298318863\n",
      "154 0.0255814790725708\n",
      "155 0.025213846936821938\n",
      "156 0.024851443246006966\n",
      "157 0.024494299665093422\n",
      "158 0.024142291396856308\n",
      "159 0.023795340210199356\n",
      "160 0.023453332483768463\n",
      "161 0.02311626635491848\n",
      "162 0.02278406172990799\n",
      "163 0.02245667576789856\n",
      "164 0.022133829072117805\n",
      "165 0.021815786138176918\n",
      "166 0.021502269431948662\n",
      "167 0.021193213760852814\n",
      "168 0.020888689905405045\n",
      "169 0.020588397979736328\n",
      "170 0.020292598754167557\n",
      "171 0.02000088058412075\n",
      "172 0.019713478162884712\n",
      "173 0.01943015679717064\n",
      "174 0.019150875508785248\n",
      "175 0.01887565106153488\n",
      "176 0.018604418262839317\n",
      "177 0.018336975947022438\n",
      "178 0.01807350106537342\n",
      "179 0.017813757061958313\n",
      "180 0.01755777932703495\n",
      "181 0.0173054076731205\n",
      "182 0.01705670729279518\n",
      "183 0.016811540350317955\n",
      "184 0.016569945961236954\n",
      "185 0.016331814229488373\n",
      "186 0.016097119078040123\n",
      "187 0.015865718945860863\n",
      "188 0.01563776098191738\n",
      "189 0.015412990935146809\n",
      "190 0.015191495418548584\n",
      "191 0.014973189681768417\n",
      "192 0.014758002944290638\n",
      "193 0.014545938931405544\n",
      "194 0.014336821623146534\n",
      "195 0.014130870811641216\n",
      "196 0.013927693478763103\n",
      "197 0.013727568089962006\n",
      "198 0.013530243188142776\n",
      "199 0.013335864059627056\n",
      "200 0.013144131749868393\n",
      "201 0.01295528281480074\n",
      "202 0.012769056484103203\n",
      "203 0.012585553340613842\n",
      "204 0.012404686771333218\n",
      "205 0.012226435355842113\n",
      "206 0.01205073669552803\n",
      "207 0.011877507902681828\n",
      "208 0.011706853285431862\n",
      "209 0.011538590304553509\n",
      "210 0.011372766457498074\n",
      "211 0.01120932400226593\n",
      "212 0.011048214510083199\n",
      "213 0.010889478027820587\n",
      "214 0.010732938535511494\n",
      "215 0.01057865098118782\n",
      "216 0.010426679626107216\n",
      "217 0.010276814922690392\n",
      "218 0.010129130445420742\n",
      "219 0.009983513504266739\n",
      "220 0.009840070270001888\n",
      "221 0.009698648937046528\n",
      "222 0.0095592699944973\n",
      "223 0.009421886876225471\n",
      "224 0.009286484681069851\n",
      "225 0.009153024293482304\n",
      "226 0.009021507576107979\n",
      "227 0.008891814388334751\n",
      "228 0.008764040656387806\n",
      "229 0.008638039231300354\n",
      "230 0.00851394236087799\n",
      "231 0.008391580544412136\n",
      "232 0.00827097613364458\n",
      "233 0.008152122609317303\n",
      "234 0.008034936152398586\n",
      "235 0.007919477298855782\n",
      "236 0.007805702276527882\n",
      "237 0.0076934900134801865\n",
      "238 0.007582935504615307\n",
      "239 0.007473910227417946\n",
      "240 0.007366502657532692\n",
      "241 0.007260675076395273\n",
      "242 0.00715631153434515\n",
      "243 0.0070535046979784966\n",
      "244 0.006952105555683374\n",
      "245 0.00685217697173357\n",
      "246 0.006753702647984028\n",
      "247 0.006656638812273741\n",
      "248 0.006560951005667448\n",
      "249 0.006466699298471212\n",
      "250 0.006373737473040819\n",
      "251 0.006282140035182238\n",
      "252 0.0061918641440570354\n",
      "253 0.0061028823256492615\n",
      "254 0.006015157792717218\n",
      "255 0.005928731057792902\n",
      "256 0.005843551829457283\n",
      "257 0.005759567022323608\n",
      "258 0.005676759872585535\n",
      "259 0.005595178343355656\n",
      "260 0.0055147744715213776\n",
      "261 0.005435488652437925\n",
      "262 0.005357389338314533\n",
      "263 0.005280383862555027\n",
      "264 0.005204509943723679\n",
      "265 0.005129706114530563\n",
      "266 0.00505600543692708\n",
      "267 0.0049833147786557674\n",
      "268 0.004911716561764479\n",
      "269 0.004841113928705454\n",
      "270 0.004771548323333263\n",
      "271 0.004702981095761061\n",
      "272 0.0046353768557310104\n",
      "273 0.004568788688629866\n",
      "274 0.004503095988184214\n",
      "275 0.004438397940248251\n",
      "276 0.00437463354319334\n",
      "277 0.004311773460358381\n",
      "278 0.0042497809045016766\n",
      "279 0.004188700579106808\n",
      "280 0.004128491971641779\n",
      "281 0.004069149494171143\n",
      "282 0.004010693170130253\n",
      "283 0.0039530545473098755\n",
      "284 0.0038962503895163536\n",
      "285 0.0038402285426855087\n",
      "286 0.0037850667722523212\n",
      "287 0.003730655647814274\n",
      "288 0.0036770296283066273\n",
      "289 0.003624211996793747\n",
      "290 0.0035721100866794586\n",
      "291 0.003520771861076355\n",
      "292 0.003470195457339287\n",
      "293 0.003420311724767089\n",
      "294 0.0033711332362145185\n",
      "295 0.0033226963132619858\n",
      "296 0.0032749627716839314\n",
      "297 0.003227891633287072\n",
      "298 0.003181472886353731\n",
      "299 0.003135761246085167\n",
      "300 0.0030906875617802143\n",
      "301 0.003046283731237054\n",
      "302 0.0030025069136172533\n",
      "303 0.002959378995001316\n",
      "304 0.0029168270993977785\n",
      "305 0.0028749010525643826\n",
      "306 0.0028336099348962307\n",
      "307 0.002792860148474574\n",
      "308 0.0027527257334440947\n",
      "309 0.0027131603565067053\n",
      "310 0.002674173330888152\n",
      "311 0.0026357576716691256\n",
      "312 0.00259786332026124\n",
      "313 0.0025605226401239634\n",
      "314 0.002523717936128378\n",
      "315 0.0024874669034034014\n",
      "316 0.002451711567118764\n",
      "317 0.0024164633359760046\n",
      "318 0.002381731756031513\n",
      "319 0.0023475049529224634\n",
      "320 0.002313749399036169\n",
      "321 0.002280516317114234\n",
      "322 0.0022477300371974707\n",
      "323 0.0022154387552291155\n",
      "324 0.00218361453153193\n",
      "325 0.002152239205315709\n",
      "326 0.002121283672749996\n",
      "327 0.0020907942671328783\n",
      "328 0.002060749800875783\n",
      "329 0.002031150972470641\n",
      "330 0.002001961227506399\n",
      "331 0.001973176607862115\n",
      "332 0.0019448439124971628\n",
      "333 0.0019168790895491838\n",
      "334 0.0018893340602517128\n",
      "335 0.0018621841445565224\n",
      "336 0.0018354151397943497\n",
      "337 0.001809037639759481\n",
      "338 0.001783037674613297\n",
      "339 0.001757425838150084\n",
      "340 0.0017321637133136392\n",
      "341 0.001707257586531341\n",
      "342 0.001682736910879612\n",
      "343 0.001658545108512044\n",
      "344 0.001634707092307508\n",
      "345 0.001611216808669269\n",
      "346 0.0015880725113674998\n",
      "347 0.0015652428846806288\n",
      "348 0.001542740734294057\n",
      "349 0.0015205828240141273\n",
      "350 0.0014987203758209944\n",
      "351 0.0014771859860047698\n",
      "352 0.001455967198126018\n",
      "353 0.0014350076671689749\n",
      "354 0.0014144033193588257\n",
      "355 0.0013940848875790834\n",
      "356 0.0013740427093580365\n",
      "357 0.0013542869128286839\n",
      "358 0.0013348228530958295\n",
      "359 0.0013156324857845902\n",
      "360 0.0012967234943062067\n",
      "361 0.0012781135737895966\n",
      "362 0.0012597268214449286\n",
      "363 0.001241637161001563\n",
      "364 0.0012237923219799995\n",
      "365 0.0012061937013641\n",
      "366 0.0011888568988069892\n",
      "367 0.0011717790039256215\n",
      "368 0.0011549273040145636\n",
      "369 0.0011383487144485116\n",
      "370 0.0011219854932278395\n",
      "371 0.0011058644158765674\n",
      "372 0.0010899655753746629\n",
      "373 0.0010743038728833199\n",
      "374 0.0010588482255116105\n",
      "375 0.001043634139932692\n",
      "376 0.0010286401957273483\n",
      "377 0.0010138658108189702\n",
      "378 0.0009992956183850765\n",
      "379 0.000984927755780518\n",
      "380 0.0009707707213237882\n",
      "381 0.0009568115347065032\n",
      "382 0.0009430712671019137\n",
      "383 0.0009295083582401276\n",
      "384 0.0009161492926068604\n",
      "385 0.0009029795764945447\n",
      "386 0.0008900109678506851\n",
      "387 0.0008772239671088755\n",
      "388 0.0008646183996461332\n",
      "389 0.000852182216476649\n",
      "390 0.0008399371290579438\n",
      "391 0.0008278677123598754\n",
      "392 0.0008159703575074673\n",
      "393 0.0008042480912990868\n",
      "394 0.000792679435107857\n",
      "395 0.0007812953554093838\n",
      "396 0.0007700678543187678\n",
      "397 0.0007590032764710486\n",
      "398 0.000748090329580009\n",
      "399 0.0007373258704319596\n",
      "400 0.0007267429027706385\n",
      "401 0.0007163002155721188\n",
      "402 0.0007060118950903416\n",
      "403 0.0006958532030694187\n",
      "404 0.0006858609849587083\n",
      "405 0.0006759940297342837\n",
      "406 0.0006662810337729752\n",
      "407 0.0006567173404619098\n",
      "408 0.0006472759996540844\n",
      "409 0.0006379662081599236\n",
      "410 0.0006288025761023164\n",
      "411 0.0006197616457939148\n",
      "412 0.0006108595407567918\n",
      "413 0.0006020645960234106\n",
      "414 0.0005934141809120774\n",
      "415 0.0005848952569067478\n",
      "416 0.000576488149818033\n",
      "417 0.000568201532587409\n",
      "418 0.0005600381991825998\n",
      "419 0.0005519844708032906\n",
      "420 0.0005440609529614449\n",
      "421 0.0005362377851270139\n",
      "422 0.0005285247461870313\n",
      "423 0.0005209339433349669\n",
      "424 0.0005134441889822483\n",
      "425 0.000506076670717448\n",
      "426 0.0004987922147847712\n",
      "427 0.0004916276666335762\n",
      "428 0.0004845609946642071\n",
      "429 0.0004776039277203381\n",
      "430 0.00047073629684746265\n",
      "431 0.0004639609542209655\n",
      "432 0.00045730560668744147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433 0.00045073291403241456\n",
      "434 0.0004442519275471568\n",
      "435 0.00043786285095848143\n",
      "436 0.0004315696132835001\n",
      "437 0.0004253626975696534\n",
      "438 0.0004192626220174134\n",
      "439 0.0004132361791562289\n",
      "440 0.00040730260661803186\n",
      "441 0.0004014422884210944\n",
      "442 0.00039568106876686215\n",
      "443 0.00038997989031486213\n",
      "444 0.00038438846240751445\n",
      "445 0.000378854398149997\n",
      "446 0.0003734110214281827\n",
      "447 0.0003680505324155092\n",
      "448 0.0003627487167250365\n",
      "449 0.00035754035343416035\n",
      "450 0.00035239694989286363\n",
      "451 0.00034734277869574726\n",
      "452 0.00034234666964039207\n",
      "453 0.00033742093364708126\n",
      "454 0.00033257753239013255\n",
      "455 0.0003278028452768922\n",
      "456 0.00032308982918038964\n",
      "457 0.00031844625482335687\n",
      "458 0.0003138630709145218\n",
      "459 0.0003093539853580296\n",
      "460 0.00030490089557133615\n",
      "461 0.0003005304606631398\n",
      "462 0.00029620761051774025\n",
      "463 0.00029195184470154345\n",
      "464 0.00028775844839401543\n",
      "465 0.0002836169151123613\n",
      "466 0.0002795481705106795\n",
      "467 0.00027553102700039744\n",
      "468 0.0002715716836974025\n",
      "469 0.0002676676376722753\n",
      "470 0.00026382209034636617\n",
      "471 0.0002600250008981675\n",
      "472 0.00025629173615016043\n",
      "473 0.0002526103926356882\n",
      "474 0.00024897680850699544\n",
      "475 0.00024539686273783445\n",
      "476 0.0002418717776890844\n",
      "477 0.00023839733330532908\n",
      "478 0.00023497475194744766\n",
      "479 0.00023158843396231532\n",
      "480 0.00022826885106042027\n",
      "481 0.00022498458565678447\n",
      "482 0.00022175181948114187\n",
      "483 0.00021856564853806049\n",
      "484 0.00021541875321418047\n",
      "485 0.0002123302547261119\n",
      "486 0.00020927500736434013\n",
      "487 0.0002062627609120682\n",
      "488 0.0002033047057921067\n",
      "489 0.00020038444199599326\n",
      "490 0.00019749840430449694\n",
      "491 0.00019466331286821514\n",
      "492 0.00019186561985407025\n",
      "493 0.00018911377992480993\n",
      "494 0.00018638736219145358\n",
      "495 0.00018371542682871222\n",
      "496 0.000181069815880619\n",
      "497 0.00017847600975073874\n",
      "498 0.00017590787319932133\n",
      "499 0.0001733774843160063\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(500):\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (after training) 4 tensor(7.9849)\n"
     ]
    }
   ],
   "source": [
    "# After training\n",
    "hour_var = torch.tensor([[4.0]])\n",
    "y_pred = model(hour_var)\n",
    "print(\"predict (after training)\",  4, model(hour_var).data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
