{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Training settings\n",
    "batch_size = 64\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(320, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    a =  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20, 20, 20])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "maxpool2d = nn.MaxPool2d(2)\n",
    "\n",
    "\n",
    "# (W−F+2P)/S+1, W=input image size, F=kernel size, P=padding, S=stride\n",
    "\n",
    "out1 = F.relu(conv1(a))\n",
    "out2 = F.relu(conv2(out1))\n",
    "\n",
    "out2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3246, 0.0000, 0.2031],\n",
       "        [1.3929, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs1 = torch.randn(2,3)\n",
    "\n",
    "a = nn.ReLU()\n",
    "b = F.relu(inputs1)\n",
    "\n",
    "a(inputs1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.2851,  0.3653,  0.1879,  0.3085,  0.1878,  0.3042,  0.5508,\n",
      "            0.2091],\n",
      "          [ 0.0793,  0.1832,  0.4591,  0.0100,  0.2695, -0.0492,  0.1785,\n",
      "            0.2773],\n",
      "          [ 0.2917,  0.2957,  0.3436,  0.4718,  0.0292,  0.3697,  0.0049,\n",
      "            0.3197],\n",
      "          [ 0.2086,  0.0569,  0.2025,  0.3329,  0.2010,  0.2945,  0.4359,\n",
      "            0.6056],\n",
      "          [ 0.0385,  0.4904,  0.1983,  0.2359,  0.5368, -0.0842,  0.3596,\n",
      "            0.1165],\n",
      "          [ 0.3602,  0.1865,  0.4262, -0.0053, -0.1352,  0.2901,  0.3490,\n",
      "            0.4335],\n",
      "          [ 0.3166,  0.2456,  0.3956,  0.3914,  0.4185,  0.3556,  0.2063,\n",
      "            0.1230],\n",
      "          [ 0.1907,  0.1539, -0.0643,  0.3272,  0.0442, -0.0361,  0.2264,\n",
      "            0.1120]]]], grad_fn=<MkldnnConvolutionBackward>)\n",
      "tensor([[[[ 0.2851,  0.3653,  0.1879,  0.3085,  0.1878,  0.3042,  0.5508,\n",
      "            0.2091],\n",
      "          [ 0.0793,  0.1832,  0.4591,  0.0100,  0.2695, -0.0492,  0.1785,\n",
      "            0.2773],\n",
      "          [ 0.2917,  0.2957,  0.3436,  0.4718,  0.0292,  0.3697,  0.0049,\n",
      "            0.3197],\n",
      "          [ 0.2086,  0.0569,  0.2025,  0.3329,  0.2010,  0.2945,  0.4359,\n",
      "            0.6056],\n",
      "          [ 0.0385,  0.4904,  0.1983,  0.2359,  0.5368, -0.0842,  0.3596,\n",
      "            0.1165],\n",
      "          [ 0.3602,  0.1865,  0.4262, -0.0053, -0.1352,  0.2901,  0.3490,\n",
      "            0.4335],\n",
      "          [ 0.3166,  0.2456,  0.3956,  0.3914,  0.4185,  0.3556,  0.2063,\n",
      "            0.1230],\n",
      "          [ 0.1907,  0.1539, -0.0643,  0.3272,  0.0442, -0.0361,  0.2264,\n",
      "            0.1120]]]], grad_fn=<MkldnnConvolutionBackward>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand(1,3,10,10)\n",
    "Conv1 = nn.Conv2d(3, 1, kernel_size=3)\n",
    "\n",
    "'''\n",
    "用nn建立的是一個class, 或說是一個NN的模組(module)，就是神經網路的一個元件，這個元件\n",
    "也擁有一些功能(就是函數)。元件的好處就是會自動設定好該元件需要的一些參數，我們可以把\n",
    "這個就當做一個nn的模組來看待，是組成整個架構的一個積木，例如我們用NN建立了一個CONV2D\n",
    "之後，他就會把需要的W，B都自動幫你設定好，\"等待\"你把資料傳入這個元件來使用。\n",
    "'''\n",
    "\n",
    "weights = Conv1.weight\n",
    "bias = Conv1.bias\n",
    "\n",
    "out = F.conv2d(inputs, weights, bias, padding=0)\n",
    "'''\n",
    "F只是NN模組中的一些函數，也是NN的模組之一。函數就是傳入參數，用來處理事情的東西，例如SIN(X)就是把X輸入算出\n",
    "正弦值。當我們要處理一個CONV2D時，就需要傳入要處理的X(輸入)，還有FILTER(就是WEIGHT)以及\n",
    "BIAS，不像在NN中都會幫我們設定好。\n",
    "'''\n",
    "\n",
    "print(Conv1(inputs))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0577, -0.0219, -0.0125,  0.0405,  0.0331, -0.1038, -0.1868,\n",
       "           -0.1346, -0.1924, -0.1329],\n",
       "          [-0.1244, -0.2014, -0.1217,  0.0326, -0.3816, -0.3146, -0.3962,\n",
       "           -0.2121, -0.0618, -0.2248],\n",
       "          [ 0.0436, -0.1476, -0.1148, -0.2295, -0.1316, -0.2823, -0.1522,\n",
       "           -0.2231, -0.4221, -0.3669],\n",
       "          [-0.3051, -0.3369, -0.2646, -0.0568, -0.1969, -0.3288, -0.2937,\n",
       "           -0.3121, -0.1392, -0.2499],\n",
       "          [ 0.1066, -0.1516, -0.2890, -0.1702, -0.4016, -0.1960, -0.1078,\n",
       "           -0.1340, -0.3794, -0.2828],\n",
       "          [-0.3336, -0.2549, -0.1678, -0.3434, -0.2246, -0.2750, -0.2880,\n",
       "           -0.3828, -0.0205, -0.1657],\n",
       "          [-0.0603, -0.1869, -0.4948, -0.1940, -0.4048, -0.4928, -0.4073,\n",
       "           -0.0831, -0.2335, -0.2368],\n",
       "          [ 0.0729, -0.3541, -0.0866, -0.2829, -0.0336, -0.1768, -0.1678,\n",
       "           -0.1430, -0.1223, -0.2598],\n",
       "          [-0.2868, -0.3148, -0.3477, -0.1064, -0.4495, -0.3307, -0.2016,\n",
       "           -0.1404, -0.3533, -0.3299],\n",
       "          [ 0.2383,  0.1219,  0.0558, -0.2275, -0.0087,  0.0481, -0.1633,\n",
       "           -0.2383,  0.0902, -0.1871]]]], grad_fn=<MkldnnConvolutionBackward>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight = torch.rand(1, 1, 3, 3)\n",
    "bias = torch.zeros(1) \n",
    "out = F.conv2d(inputs, weights, bias, padding=1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "builtin_function_or_method"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.max_pool2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
